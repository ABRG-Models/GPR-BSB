{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab book\n",
    "\n",
    "## 2017-07-10\n",
    "\n",
    "A trial at using a python notebook as a labbook, recognising that a lab book, with dates and a time line, and the display of certain results is quite distinct from a \"working\" python notebook which might be used for analysis of results.\n",
    "\n",
    "To summarise progress so far:\n",
    "\n",
    "I have reproduced Basab's basal ganglia model using SpineML, which she has implemented for SpiNNaker. To achieve this, I've had to find out about the working of SpiNNaker models, and have led myself down a couple of blind alleys, but have learned the following:\n",
    "\n",
    "SpiNNaker implements an Izhikevich model which can be very closely modelled on SpineML.\n",
    "\n",
    "SpiNNaker implements a conductance based synapse model which adds a conductance with each spike. The amount of conductance added per spike depends on the source of the spike as well as the destination. Each spike is therefore what in the SpineML world we call an \"impulse\".\n",
    "\n",
    "Although there is no mathematical limit applied to the size of the excitatory or inhibitory conductance at the receiving neuron, SpiNNaker has a built-in limit due to the impulse being encoded in a fixed-width representation.\n",
    "\n",
    "To reproduce this limit, I have coded up SpiNNaker-like synapse models GABASpiNN, GABASpiNNgbar and AMPASpiNN, AMPASpiNNgbar. The gbar versions of these synapse models are for use in event based models - an incoming spike causes an increase in the conductance, $g$ of $\\bar{g}$. The non-gbar versions are for using impulse based models, where the $\\bar{g}$ is incorporated into the impulse. Both versions of each synapse model have a paramter g_limit, which would usually be set to 256, 512 or 1024 to match the kind of maximums which the run-time defined, fixed-width scaling applies. GABASpiNN and AMPASpiNN are functionally the same; I could have created just \"SpiNNSyn\" and \"SpiNNSyngbar\" components.\n",
    "\n",
    "In the notebook GPR-BSB-1CH, I've set up code to run some of the experiments specified in the SpineML models bgbsb1 (which is event based) and bgbsb1_impt (impulse \"pass-through\"). The input is set up as per Basab's experiments; with  700 ms to start with no input, 5200 ms of 3Hz Poisson spiking and a final 100 ms of no input to make 6 s total.\n",
    "\n",
    "As in Basab's experiments, I have set the exact connectivity to be selected with a time-generated seed at run-time and the Poisson spike trains also have a different, time-generated seed on each run.\n",
    "\n",
    "I have written R scripts to do some bootstrap analyses on the spike rates generated to determine if the models are statistically different or not.\n",
    "\n",
    "What I have found is that the two different versions of the 1 channel SpineML model, and the SpiNNaker version of the 1 channel SpineML model all generate statistically significantly different population firing rates.\n",
    "\n",
    "### 13:00\n",
    "\n",
    "Just received updated information on the g_limits that SpiNNaker applies to the model. I've applied these in the bgbsb1_impt model. In the bgbsb1 and bgbsb3 models, I've set all the g_limits to 256 uS. I'm going to re-run my \"run the model 30 times\" scheme on bgbsb1_impt now. See commit d2d544b for results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
